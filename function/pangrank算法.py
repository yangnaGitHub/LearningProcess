# -*- coding: utf-8 -*-
"""
Created on Thu Jan 24 10:53:52 2019

@author: natasha_yang

@e-mail: ityangna0402@163.com
"""

#若网址A可以直接通过点击进B,则A出度一条边到B入度,多个相同链接不重复计算边
#所以整个web被抽象成一个有向图
#假设当一个用户停留在某个网址跳转到这个网址链接的其他网址上的概率是相同的
#  A    B    C  D
#[[0,   0.5, 0, 0.5], =>A出度到B,C,D的概率是1/3
# [1/3, 0,   0, 0.5], =>B出度到A,C的概率是1/2
# [1/3, 0.5, 0, 0  ], =>C出度到D的概率是1
# [1/3, 0,   1, 0  ]] =>D出度到A,B的概率是1/2
#初始的时候访问每个页面的概率是1/N

import numpy as np
graph = np.array([[0, 1/2.0, 0, 1/2.0], [1/3.0, 0, 0, 1/2.0], [1/3.0, 1/2.0, 0, 0], [1/3.0, 0, 1, 0]])
init_m = np.array([[1/4.0], [1/4.0], [1/4.0], [1/4.0]])
for index in range(10000):
    init_m = graph*init_m
    if 0 == index % 1000:
        print(init_m)

#Dead Ends:某些网址不存在外链=>网页节点矩阵M中是否有一列全部是0,有的话就将这一列的值全部替换成1/n
#Spider Traps及平滑处理
#如果把真实的web组织成转移矩阵,那么这个转移矩阵会是一个极其稀疏的矩阵,极其稀疏的矩阵迭代乘会使得结果变得非常不平滑
#一种叫做Spider Traps的节点(网址有外链,但是只链接自己)会加剧这种不平滑
#认为任何一个页面都有可能以一个极小的概率瞬间转移到另外一个随机页面
#迭代公式:(1-beta)*graph*init_m + beta*(E/N) =>E是N维的单位向量
import numpy as np
graph = np.array([[0, 1/2.0, 0, 1/2.0], [1/3.0, 0, 0, 1/2.0], [1/3.0, 1/2.0, 0, 0], [1/3.0, 0, 1, 0]])
init_m = np.array([[1/4.0], [1/4.0], [1/4.0], [1/4.0]])
beta = 0.2
for index in range(10000):
    init_m = (1-beta)*graph*init_m + beta*np.array([[1/4]]*4)#N=4
    if 0 == index % 1000:
        print(init_m)

#当一个网页被更多网页所链接的时候其排名会靠前
#排名高的网页应该具有更大的表决权,即当一个网页被排名高的网页所链接的时候,其重要性也对应提高
#一个网页的排名=所有链接到该网页的加权排名总和
#PR_i = PR_j1(j1节点的PR值)/O_j1(j1节点总的出度数,j1会出度到i) + PR_j2/O_j2 + ... + PR_jn/O_jn
#先有鸡还是先有蛋=>power iteration
#power iteration是指给定一个初始的P_0,然后通过多轮迭代求解,最后收敛
#P_K = M(转移矩阵)*P_K-1
#每行至少存在一个非零值(必须存在一个外链接,就是必须有出度),有向图必须是强联通的
#把全为0的行替换为E/n,E为单位矩阵
#非强联通就是平滑
        
####textrank####
#一种基于文本的排序算法