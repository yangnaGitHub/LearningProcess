# -*- coding: utf-8 -*-
"""
Created on Mon Mar 13 09:39:03 2017

@author: natasha1_Yang
"""

#LDA的DA是“Dirichleet分布”的缩写
#Dirichleet分布是Beta分布推广到多维的情况
#Beta分布和Γ函数有关系,且它是二项分布的共轭先验分布
#Γ(x) = (x-1)!
#Γ(x)/Γ(x-1) = x-1
#Beta分布:x^(α-1)(1-x)^(β-1)/B(α, β) x=[0, 1]
#B(α, β) = Γ(α)Γ(β)/Γ(α + β)
#后验概率P(θ|x)和先验概率p(θ)满足同样的分布律,先验分布和后验分布被叫做共轭分布,先验分布叫做似然函数的共轭先验分布
#对于高斯分布,σ的共轭先验分布是伽马分布
#Beta分布是二项分布的共轭先验分布
#对于投掷硬币x是正面向上的概率x改成文章属于主题0的事件==>主题模型
#对称Dirichleet分布只是α一样,某文档属于各个主体的概率Pk是不同的
#α=1时:退化为均匀分布,则先验认为一篇文档对应所有主题的概率都相同
#α>1时:p1=p2=…=pk的概率增大,采样到各个主题相等的概率最大,也有可能采样到的主题概率不相等
#α<1时:pi =1,p非i =0的概率增大,先验认为一篇文档只聚类一个/一部分主题的概率大
#LDA是个无监督的模型,LDA是把所有的文档做了个概率化的聚类,词和文档之间增加的主题就是增加了一个隐变量
#需要准备Dirichleet分布的参数α和主题的个数K
#假设一个文档有100W个词,那这个文档就可以看成是个100W维的向量,如果主题一共有1000个,LDA的结果就是把这个文档从100W维降到了1000维(降维)
#α表达了不同文档间主题是否鲜明,β度量了有多少近义词能够属于同一个类别
#若想知道一个词的主题,那就看与其相邻的词的主题,与这个词在同一个文档的词都算与其相邻
#直接计算没有这个词的时候其他所有词构成的整篇文档属于哪个主题,那这个词就属于哪个主题